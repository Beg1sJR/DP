import gdown
import openai
import faiss
import numpy as np
import sqlite3
import re

import requests
from sentence_transformers import SentenceTransformer
from sqlalchemy.orm import Session
from backend.database import SessionLocal
from backend.models import LogAnalysis
import os
from dotenv import load_dotenv
from collections import Counter
import json

load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
ALERT_THRESHOLD = 70  # –ø—Ä–æ—Ü–µ–Ω—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
INDEX_PATH = os.path.join(os.path.dirname(__file__), "logs_faiss.index")
IDS_PATH = os.path.join(os.path.dirname(__file__), "log_ids.npy")
DRIVE_FILE_ID = os.getenv("FAISS_INDEX_ID")  # ID —Ñ–∞–π–ª–∞ –Ω–∞ Google Drive (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –∞–≤—Ç–æ—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ)

# INDEX_PATH = os.path.join(os.path.dirname(__file__), "logs_faiss.index")
FILE_ID = "1THFPYvsGfgxbSQvNc8SMYh0CtsWpBnBo"

if not os.path.exists(INDEX_PATH):
    print("–§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–∫–∞—á–∏–≤–∞–µ–º –∏–∑ Google Drive...")
    gdown.download(f"https://drive.google.com/uc?id={FILE_ID}", INDEX_PATH, quiet=False)
    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ —Å–∫–∞—á–∞–Ω –±–∏–Ω–∞—Ä–Ω–∏–∫, –∞ –Ω–µ html:
    with open(INDEX_PATH, "rb") as f:
        head = f.read(100)
        print("First 100 bytes:", head)
# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ ID-—Ñ–∞–π–ª–∞
if not os.path.exists(IDS_PATH):
    print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {IDS_PATH}. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ log_ids.npy –ª–µ–∂–∏—Ç —Ä—è–¥–æ–º —Å logs_faiss.index!")
    raise FileNotFoundError(f"{IDS_PATH} not found")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
client = openai.OpenAI(api_key=OPENAI_API_KEY)
model = SentenceTransformer("all-MiniLM-L6-v2")

# –û—Ç–ª–∞–¥–∫–∞: –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã –∏–Ω–¥–µ–∫—Å–∞
with open(INDEX_PATH, "rb") as f:
    head = f.read(100)
    print("First 100 bytes of logs_faiss.index:", head)

# –ó–∞–≥—Ä—É–∑–∫–∞ FAISS –∏–Ω–¥–µ–∫—Å–∞ –∏ ID
index = faiss.read_index(INDEX_PATH)
ids = np.load(IDS_PATH)

def get_similar_logs_pg(input_text: str, top_k: int = 3):
    query_vec = model.encode([input_text])
    D, I = index.search(query_vec, top_k)

    db: Session = SessionLocal()
    results = []

    for idx in I[0]:
        log_id = int(ids[idx])
        entry = db.query(LogAnalysis).filter_by(id=log_id).first()

        if entry:
            results.append({
                "log": entry.log_text,
                "type": entry.attack_type,
                "mitre": entry.mitre_id,
                "recommendation": entry.recommendation,
            })

    db.close()
    return results

def build_prompt(similar_logs, input_log):
    context = "\n\n".join([
        f"–ü—Ä–∏–º–µ—Ä:\n–õ–æ–≥: {e['log']}\n–¢–∏–ø: {e['type']}\nMITRE: {e['mitre']}\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {e['recommendation']}"
        for e in similar_logs
    ])
    return f"""
–¢—ã ‚Äî SecurityGPT, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤—ã–π –ª–æ–≥.

{context}

–ù–æ–≤—ã–π –ª–æ–≥:
{input_log}

–î–∞–π –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
–¢–∏–ø –∞—Ç–∞–∫–∏: ...
MITRE: ...
–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: ...%
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: ...
"""

def analyze_log_with_gpt(input_log: str) -> str:
    try:
        similar_logs = get_similar_logs_pg(input_log)
        if similar_logs:
            context = "\n\n".join([
                f"–ü—Ä–∏–º–µ—Ä:\n–õ–æ–≥: {e['log']}\n–¢–∏–ø: {e['type']}\nMITRE: {e['mitre']}\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {e['recommendation']}"
                for e in similar_logs
            ])
        else:
            context = "–ù–µ—Ç –ø–æ—Ö–æ–∂–∏—Ö –ª–æ–≥–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ª–æ–≥ –±–µ–∑ –ø—Ä–∏–º–µ—Ä–æ–≤."

        prompt = f"""
–¢—ã ‚Äî SecurityGPT, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤—ã–π –ª–æ–≥.

{context}

–ù–æ–≤—ã–π –ª–æ–≥:
{input_log}

–î–∞–π –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
–¢–∏–ø –∞—Ç–∞–∫–∏: ...
MITRE: ...
–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: ...%
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: ...
"""

        print("üì§ Prompt –≤ analyze_log_with_gpt:\n", prompt)

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=400
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT:", str(e))
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback-–æ—Ç–≤–µ—Ç
        return """–¢–∏–ø –∞—Ç–∞–∫–∏: –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
MITRE: T1078
–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: 55%
–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ IP –∏ –∑–∞–±–ª–æ–∫–∏—Ä—É–π—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–∏."""

def parse_gpt_response(response_text: str) -> dict:
    # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    attack_type = "–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"
    mitre = "‚Äî"
    recommendation = "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥ –≤—Ä—É—á–Ω—É—é. GPT –Ω–µ –¥–∞–ª –ø–æ–Ω—è—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."
    probability = 50

    try:
        # –ì–∏–±–∫–∏–µ —Ä–µ–≥—É–ª—è—Ä–∫–∏
        type_match = re.search(r"–¢–∏–ø –∞—Ç–∞–∫–∏\s*:\s*(.+)", response_text, re.IGNORECASE)
        mitre_match = re.search(r"MITRE\s*:\s*(.+)", response_text, re.IGNORECASE)
        prob_match = re.search(r"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å\s*:\s*(\d+)", response_text, re.IGNORECASE)
        rec_match = re.search(r"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\s*:\s*((?:.|\n)+)", response_text, re.IGNORECASE)

        if type_match:
            attack_type = type_match.group(1).strip()

        if mitre_match:
            mitre = mitre_match.group(1).strip()

        if prob_match:
            probability = int(prob_match.group(1))

        if rec_match:
            recommendation = rec_match.group(1).strip()

    except Exception as e:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ GPT-–æ—Ç–≤–µ—Ç–∞:", str(e))

    return {
        "attack_type": attack_type,
        "mitre_id": mitre,
        "probability": probability,
        "recommendation": recommendation
    }

def forecast_attack_with_gpt(logs_text: str) -> dict | None:
    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –í–æ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏:

{logs_text}

–ù–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∂–∏ —Å–ª–µ–¥—É—é—â—É—é –≤–æ–∑–º–æ–∂–Ω—É—é –∫–∏–±–µ—Ä–∞—Ç–∞–∫—É. –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ JSON, –±–µ–∑ markdown:
{{
  "type": "–Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ç–∞–∫–∏",
  "confidence": 0-100,
  "expected_time": "–≤—Ä–µ–º—è –≤ ISO-—Ñ–æ—Ä–º–∞—Ç–µ",
  "target_ip": "–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π IP",
  "reasoning": "–ø–æ—è—Å–Ω–µ–Ω–∏–µ"
}}
"""

    print("üì§ Prompt –≤ forecast_attack_with_gpt:\n", prompt)

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=500
        )

        content = response.choices[0].message.content.strip()
        print("üì• –û—Ç–≤–µ—Ç –æ—Ç GPT:\n", content)

        # –£–¥–∞–ª—è–µ–º Markdown-–æ–±–µ—Ä—Ç–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()

        result = json.loads(content)

        required_keys = ["type", "confidence", "expected_time", "target_ip", "reasoning"]
        if all(k in result for k in required_keys):
            return result
        else:
            print("‚ö†Ô∏è –ù–µ–ø–æ–ª–Ω—ã–π JSON –æ—Ç GPT:", result)
            return None

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT:", str(e))
        return None

def generate_report_summary(logs: list[LogAnalysis]) -> str:
    if not logs:
        return "–ù–µ—Ç –ª–æ–≥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥."

    log_texts = [log.log_text for log in logs[:20]]

    # –°–±–æ—Ä –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    attack_counter = Counter([l.attack_type for l in logs if l.attack_type and l.attack_type != "–ù–µ—Ç –∞—Ç–∞–∫–∏"])
    mitre_counter = Counter([l.mitre_id for l in logs if l.mitre_id])
    country_counter = Counter([l.country for l in logs if l.country])
    city_counter = Counter([l.city for l in logs if l.city])
    ip_counter = Counter([l.ip for l in logs if l.ip])
    high_risk_count = sum(1 for l in logs if l.probability >= 70)

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = f"""
üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–æ–≥–æ–≤: {len(logs)}
üö® –ê—Ç–∞–∫ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º: {high_risk_count}

üõ° –¢–û–ü –∞—Ç–∞–∫:
{chr(10).join(f"- {k}: {v}" for k, v in attack_counter.most_common(5))}

üéØ –¢–û–ü MITRE:
{chr(10).join(f"- {k}: {v}" for k, v in mitre_counter.most_common(5))}

üåç –¢–û–ü —Å—Ç—Ä–∞–Ω:
{chr(10).join(f"- {k}: {v}" for k, v in country_counter.most_common(3))}

üèô –¢–û–ü –≥–æ—Ä–æ–¥–æ–≤:
{chr(10).join(f"- {k}: {v}" for k, v in city_counter.most_common(3))}

üîÅ –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è IP:
{chr(10).join(f"- {k}: {v} —Ä–∞–∑" for k, v in ip_counter.most_common(3))}
"""

    prompt = f"""
–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ SOC. –í–æ—Ç —Å–ø–∏—Å–æ–∫ –ª–æ–≥–æ–≤ (–¥–æ 20):

{chr(10).join(log_texts)}

üìà –í–æ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
{stats}

–°—Ñ–æ—Ä–º–∏—Ä—É–π —É–ø—Ä–∞–≤–ª–µ–Ω—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç:
- –∫–∞–∫–∏–µ —Ç–∏–ø—ã –∞—Ç–∞–∫ –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç
- –∫–∞–∫–∏–µ —É–≥—Ä–æ–∑—ã —Å—Ç–æ–∏—Ç –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å
- —á—Ç–æ –º–æ–∂–µ—Ç —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ–≤–∞—Ç—å –æ –º–∞—Å—Å–æ–≤—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö –≤–∑–ª–æ–º–∞
- —á—Ç–æ –ø–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—à—å –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å

–û—Ç–≤–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤—å –∫–∞–∫ –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–æ–∫–ª–∞–¥ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ (–º–æ–∂–Ω–æ —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏).
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=800
    )

    return response.choices[0].message.content.strip()

def explain_log_with_gpt(log_text: str) -> str:
    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –ª–æ–≥:

{log_text}

–û–±—ä—è—Å–Ω–∏, —á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–∑–º–æ–∂–Ω–æ–π –∞—Ç–∞–∫–∏ —Ç—ã –≤–∏–¥–∏—à—å,
–∏ –∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è —Å—Ç–æ–∏—Ç –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å.

–û—Ç–≤–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤—å –≤ 3-—Ö —á–∞—Å—Ç—è—Ö:
1. –í–æ–∑–º–æ–∂–Ω—ã–π —Ç–∏–ø –∞—Ç–∞–∫–∏
2. –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=500
    )

    return response.choices[0].message.content.strip()

def notify_telegram(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("‚ö†Ô∏è Telegram: –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ –∑–∞–¥–∞–Ω—ã.")
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message
    }

    try:
        response = requests.post(url, data=payload)
        if response.status_code != 200:
            print("‚ùå Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ:", response.text)
        else:
            print("‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ Telegram –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.")
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram:", str(e))